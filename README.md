# Bias Diagnostics Engine Starter Kit Contents
1.	Team Member Resources 
2.	Overview
3.	Video – How Technology can help 
4.	The idea
5.	How it works
6.	Diagrams
7.	Documents
8.	Datasets
9.	Technology
10.	Getting started
11.	Resources
12.	License


## Update your starter kits in GitHub with the following information (Please keep your repositories private and those who need access will request it):
1.	Team member validation (please note those who are no longer able to remain active throughout the fortification phase) 
	= Confirmed as working member for Externalization Phase
		Denise Knorr	Product Manager
		Boz Handy Bosman	AoT Master Inventor (AIF360)
		Sam Hoffman	AIF360 Developer
		Hema Veeradhi	Red Hat Software Engineer
		Kate Tereshchenko	Cloud Data Scientist
		Misra Turp	GBS Data Scientist
		Ann Marie Fred	CFC Sentencing Reform Team
		Demi Ajayi	Prod Designer – AI Natural Language
		Otis Smart	AI Data Scientist - Machine Learning
			Developer / Coder
			Developer / Architect 

2.	OVERVIEW: Short clear description: what is the problem and how can technology help?
a.	Solution Name and short description
1)	IBM Racial Disparity & Bias Diagnostics Engine  
a)	AI Fairness 360 sourced functionality refined to specifically isolate racial disparity in technology enabled outcomes and sufficiently diagnose bias related causes for the disparity so that remediation can be recommended, and outcomes subsequently monitored and measured for effectiveness  

b.	What is the Problem:  
1)	A new class of “anti-bias / anti-Systemic Racism” solutions (aka Call for Code EmbRace solutions) strives to have outcomes that can be mathematically assessed and validated as “Bias Free” 
a)	This new class of solutions that prioritize the minimization of outcomes infected by implicit racial bias will need leading edge technology and newly developed interface protocols that can effectively serve as a universally accepted fair and “Credible Arbiter” of bias and other variables that might negatively contribute to racially-driven disparity in outcomes.
b)	Without validated and benchmarked models for consistent attribution and remediation of bias, the full range of new and innovative anti-bias solutions will have diminished ability to deliver outcomes that are universally seen as mathematically and repeatably accurate in diagnosing and remediating bias. 
•	A random / one-off approach to detecting and remediating bias will not be sufficient to drive outcomes accepted / acknowledged as bias-free across a large ecosystem of a new class of anti-bias solutions 
c)	Furthering the problem is that effects of bias can be fed into a single solution’s outcomes via multiple inputs / steps in that single solution’s processes, while at the same time some steps or processes associated with the solution’s outcome may be mathematically bias-free or neutral.  
•	This means that the bias diagnostics capabilities need to be sufficient to assess the cumulative effect of multiple sources of bias throughout the entire “process pipeline” within a single solution, so that if any single “bias-infected” input source or data set within the solution’s process pipeline goes undiagnosed, the outcome may still reflect elements of racial bias. In other words, neutral processes are not sufficient in-and-of themselves to prevent implicit racial bias from infecting a solution’s outcomes. 
c.	How can Technology Help 
1)	By leveraging existing (enhanced) IBM technologies like AI Fairness 360, IBM can provide benchmarked hardened models and interface protocols for disparity and bias diagnostics functionality (aka a full functioning Bias Diagnostics Engine) that can be universally applied via Open source cloud enablement by a varied range of internal and external 3rd party solutions targeting bias-free outcomes, 
2)	IBM technology can serve as a scientifically sourced “credible” arbiter of disparity and racial bias by leveraging IBM’s unique and deep brain-trust of research and expertise needed to adequately assign algorithms sufficient to digitize and quantify bias infused context and concepts. 
3)	Privacy Preserving will be required due to the nature of most data sets, so IBM cloud Security will be a critical technology enabler for this new class of anti-bias / anti-racism solutions and required for the Bias Engine to function optimally since many of the most relevant data sets needed are those that will require maximum levels of security and privacy similar to the levels of security IBM provides to Financial and Public Sector solutions and platforms. 

3.	2 min VIDEO – The idea / elevator pitch by Boz 

4.	The idea: the elevator pitch of your solution. Explain how it works- What would be a successful uses of the technology , and provide guidance to the developer (standards/protocols; documents)

A.	Denise elevator pitch diagram of high level process flow 

5.	HOW IT WORKS – Boz 
•	Skills and IBM Cloud or open source services - what are the key technology areas  an external developer needs  to know in order to build upon this idea? Please be sure to call out the open source technologies it would leverage. 
•	Privacy preserving  is part of Bias engine process
6.	 Reference materials - data sets, research, guidance, standards, and documents - Boz


7.	Architecture diagrams - look at the solution end to end (for example): please note, it doesn't have to be as polished as this example. We have designers who can help
A.	Funnel diagrams – both versions funnel and boxes 
8.	Working code – (Sam) …….details on how to get started (i.e. register for a cloud account and choose a common service) and how to assemble the building blocks of your solution using IBM and open source technology. 


9.	Suggestions on how to take the idea in other directions - this points developer/organizations in ways to connect the dots and create solutions to address other use cases; e.g. swapping out data sets – 
A.	Blockchain to establish consensus about data sharing. 
B.	Accountability Scoring
C.	Clean Media Ecosystem Container – Bias detection + Misinformation flagging + Misinformation filters + Accountability Scores



